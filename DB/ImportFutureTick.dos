
def findAllCSVFiles(path) {
    dirContent = files(path)
    result = []
    
    for (i in 0:size(dirContent)) {
        item = dirContent[i]
        fullPath = path + "/" + item.filename
        if (item.isDir) {
            temp = findAllCSVFiles(fullPath)
            for(j in 0:size(temp)) {
                result.append!(temp[j])
            }
        } else {
            if (substr(fullPath,strlen(fullPath)-4) == ".csv") {
                result.append!(fullPath)
            }
        }
    }

    return result
}

def loadCSVFile(path, dbTableHandle) {
    csvSchema = extractTextSchema(path, delimiter=',')
    csvData = loadText(path, schema=csvSchema, delimiter=',')

    addColumn(csvData, `FileName, SYMBOL) 

    pos = 0
    f = ""
    do {
        pos = regexFind(path,"/",pos)
        if(pos != -1) {
            pos += 1
            f = substr(path,pos)
        }
    } while(pos != -1)

    UPDATE csvData
    SET 
    FileName = f

    tableInsert(dbTableHandle,csvData)
}

def batchLoadCSV(filesPath,dbTableHandle) {
    for(i in 0:size(filesPath)) {
         loadCSVFile(filesPath[i],dbTableHandle)
    }
}

def waitForJobs(mutable jobIds) {
    again = true
    f = 0
    do {
         again = false
         for(i in 0:size(jobIds)) {
            if(jobIds[i] == NULL)
               continue
            res = getJobStatus(jobIds[i])
            if(res.endTime == NULL) {
                again = true
                //print(jobIds[i] + " is running! ")
            } else {
                f+=1
                print("Finish (" + f + "/" + size(jobIds)+ ") :" + jobIds[i] + " completed at " + string(res.endTime))
                if(res.errorMsg != NULL)
                    print("Error in job:" + jobIds[i] + string(res.errorMsg))
                jobIds[i] = NULL
            }
         }
         sleep(2000)

    } while(again)
   
    print("All Done!")
}

csvFilePath = "E:/DolphinDB/201101"
csvFiles = findAllCSVFiles(csvFilePath)
dbTable = loadTable("dfs://tick_data", "raw")

batchSize = 100
if(size(csvFiles) <= batchSize) {
    for(i in 0:size(csvFiles)) {
       loadCSVFile(csvFiles[i],dbTable)
       print("Finish (" + i + "/" + size(csvFiles)+ ") :" + csvFiles[i])
    }
} else {
    batchFiles = cut(csvFiles,batchSize)
    jobsID = []
    for(j in 0:size(batchFiles)) {
        jobsID.append!(submitJob("Job_" + j,"Job_" + j, batchLoadCSV,batchFiles[j],dbTable))
    }

    print("Total csv files:" + size(csvFiles) + " Batch size:" + batchSize + " Total batch jobs: " + size(jobsID))
    waitForJobs(jobsID)
}

//submitJob()

//temp = "E:/DolphinDB/201101/20110104/b主力连续_20110104.csv"

 

